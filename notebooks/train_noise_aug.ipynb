{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13452833,"sourceType":"datasetVersion","datasetId":8539274},{"sourceId":13453138,"sourceType":"datasetVersion","datasetId":8539487}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:56:24.482614Z","iopub.execute_input":"2025-10-21T13:56:24.483446Z","iopub.status.idle":"2025-10-21T13:56:24.487801Z","shell.execute_reply.started":"2025-10-21T13:56:24.483418Z","shell.execute_reply":"2025-10-21T13:56:24.486988Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class ECGCNN(nn.Module):\n    def __init__(self, num_classes=5):\n        super(ECGCNN, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=2)\n        self.bn1 = nn.BatchNorm1d(32)\n        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n        self.fc1 = nn.Linear(128 * 27, 256)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, num_classes)\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:56:36.407124Z","iopub.execute_input":"2025-10-21T13:56:36.407786Z","iopub.status.idle":"2025-10-21T13:56:36.418077Z","shell.execute_reply.started":"2025-10-21T13:56:36.407756Z","shell.execute_reply":"2025-10-21T13:56:36.416966Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"data_path = '/kaggle/input/ecg-datasets/ecg_clean.csv'\ndf = pd.read_csv(data_path)\nprint(f\"Dataset loaded: {df.shape}\")\n\n# Encode labels\nif df['label'].dtype == 'object':\n    le = LabelEncoder()\n    df['label'] = le.fit_transform(df['label'])\n    print(f\"Label encoding: {dict(zip(le.classes_, range(len(le.classes_))))}\")\n\n# Ensure numeric\nfeature_cols = [col for col in df.columns if col != 'label']\nfor col in feature_cols:\n    df[col] = pd.to_numeric(df[col], errors='coerce')\ndf = df.dropna()\n\nX = torch.tensor(df.drop('label', axis=1).values, dtype=torch.float32)\ny = torch.tensor(df['label'].values, dtype=torch.long)\nX = (X - X.mean(dim=0)) / (X.std(dim=0) + 1e-8)\n\nprint(f\"X shape: {X.shape}, y shape: {y.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:56:50.162273Z","iopub.execute_input":"2025-10-21T13:56:50.162641Z","iopub.status.idle":"2025-10-21T13:56:56.231328Z","shell.execute_reply.started":"2025-10-21T13:56:50.162620Z","shell.execute_reply":"2025-10-21T13:56:56.230127Z"}},"outputs":[{"name":"stdout","text":"Dataset loaded: (100033, 217)\nLabel encoding: {'A': 0, 'L': 1, 'N': 2, 'R': 3, 'V': 4}\nX shape: torch.Size([100033, 216]), y shape: torch.Size([100033])\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def add_noise(signal, snr_db):\n    signal_power = torch.mean(signal ** 2)\n    noise_power = signal_power / (10 ** (snr_db / 10))\n    noise = torch.randn_like(signal) * torch.sqrt(noise_power)\n    return signal + noise\n\nclass NoisyDataset(torch.utils.data.Dataset):\n    def __init__(self, X, y, add_noise_prob=0.7):\n        self.X = X\n        self.y = y\n        self.add_noise_prob = add_noise_prob\n        self.snr_levels = [0, 3, 6, 9, 12, 15, 18, 20]\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        x = self.X[idx]\n        y = self.y[idx]\n        \n        if torch.rand(1).item() < self.add_noise_prob:\n            snr = np.random.choice(self.snr_levels)\n            x = add_noise(x, snr)\n        \n        return x, y\n\ndataset = NoisyDataset(X, y, add_noise_prob=0.7)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n\nprint(f\"Training samples: {len(train_dataset)}\")\nprint(f\"Validation samples: {len(val_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:57:01.782916Z","iopub.execute_input":"2025-10-21T13:57:01.783453Z","iopub.status.idle":"2025-10-21T13:57:01.805525Z","shell.execute_reply.started":"2025-10-21T13:57:01.783428Z","shell.execute_reply":"2025-10-21T13:57:01.804799Z"}},"outputs":[{"name":"stdout","text":"Training samples: 80026\nValidation samples: 20007\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model = ECGCNN(num_classes=5).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nbest_val_acc = 0.0\nepochs = 30\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING CNN WITH NOISE AUGMENTATION\")\nprint(\"=\"*60 + \"\\n\")\n\nfor epoch in range(epochs):\n    model.train()\n    train_loss, train_correct, train_total = 0, 0, 0\n    \n    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        train_total += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n    \n    train_acc = train_correct / train_total\n    \n    model.eval()\n    val_correct, val_total = 0, 0\n    \n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n    \n    val_acc = val_correct / val_total\n    \n    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n    \n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), '/kaggle/working/cnn_noise_aug_best.pth')\n        print(f\"âœ… Saved! Val Acc: {val_acc:.4f}\\n\")\n\nprint(f\"\\nðŸŽ¯ Best Validation Accuracy: {best_val_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T13:57:13.962767Z","iopub.execute_input":"2025-10-21T13:57:13.963223Z","iopub.status.idle":"2025-10-21T14:18:38.363533Z","shell.execute_reply.started":"2025-10-21T13:57:13.963198Z","shell.execute_reply":"2025-10-21T14:18:38.362620Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTRAINING CNN WITH NOISE AUGMENTATION\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30 - Train Acc: 0.9640 | Val Acc: 0.9861\nâœ… Saved! Val Acc: 0.9861\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/30 - Train Acc: 0.9789 | Val Acc: 0.9872\nâœ… Saved! Val Acc: 0.9872\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/30 - Train Acc: 0.9823 | Val Acc: 0.9886\nâœ… Saved! Val Acc: 0.9886\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/30 - Train Acc: 0.9847 | Val Acc: 0.9885\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/30 - Train Acc: 0.9859 | Val Acc: 0.9899\nâœ… Saved! Val Acc: 0.9899\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/30 - Train Acc: 0.9871 | Val Acc: 0.9911\nâœ… Saved! Val Acc: 0.9911\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/30 - Train Acc: 0.9875 | Val Acc: 0.9896\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/30 - Train Acc: 0.9883 | Val Acc: 0.9910\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/30 - Train Acc: 0.9889 | Val Acc: 0.9919\nâœ… Saved! Val Acc: 0.9919\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:41<00:00, 30.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/30 - Train Acc: 0.9896 | Val Acc: 0.9907\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/30 - Train Acc: 0.9899 | Val Acc: 0.9915\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/30 - Train Acc: 0.9902 | Val Acc: 0.9919\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/30 - Train Acc: 0.9907 | Val Acc: 0.9917\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/30 - Train Acc: 0.9914 | Val Acc: 0.9922\nâœ… Saved! Val Acc: 0.9922\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/30 - Train Acc: 0.9908 | Val Acc: 0.9920\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/30 - Train Acc: 0.9919 | Val Acc: 0.9921\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/30 - Train Acc: 0.9920 | Val Acc: 0.9920\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/30 - Train Acc: 0.9925 | Val Acc: 0.9922\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/30 - Train Acc: 0.9922 | Val Acc: 0.9927\nâœ… Saved! Val Acc: 0.9927\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/30 - Train Acc: 0.9921 | Val Acc: 0.9917\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/30 - Train Acc: 0.9932 | Val Acc: 0.9919\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/30 - Train Acc: 0.9936 | Val Acc: 0.9923\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/30 - Train Acc: 0.9934 | Val Acc: 0.9924\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/30 - Train Acc: 0.9939 | Val Acc: 0.9930\nâœ… Saved! Val Acc: 0.9930\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27/30 - Train Acc: 0.9939 | Val Acc: 0.9922\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29/30 - Train Acc: 0.9940 | Val Acc: 0.9926\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1251/1251 [00:40<00:00, 30.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30/30 - Train Acc: 0.9937 | Val Acc: 0.9922\n\nðŸŽ¯ Best Validation Accuracy: 0.9932\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"def evaluate_dataset(model, csv_path):\n    df = pd.read_csv(csv_path)\n    \n    if df['label'].dtype == 'object':\n        le = LabelEncoder()\n        df['label'] = le.fit_transform(df['label'])\n    \n    feature_cols = [col for col in df.columns if col != 'label']\n    for col in feature_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    df = df.dropna()\n    \n    X = torch.tensor(df.drop('label', axis=1).values, dtype=torch.float32)\n    y = torch.tensor(df['label'].values, dtype=torch.long)\n    X = (X - X.mean(dim=0)) / (X.std(dim=0) + 1e-8)\n    \n    dataset = TensorDataset(X, y)\n    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n    \n    model.eval()\n    correct, total = 0, 0\n    \n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T14:19:22.902246Z","iopub.execute_input":"2025-10-21T14:19:22.902772Z","iopub.status.idle":"2025-10-21T14:19:22.909106Z","shell.execute_reply.started":"2025-10-21T14:19:22.902746Z","shell.execute_reply":"2025-10-21T14:19:22.908356Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model = ECGCNN(num_classes=5).to(device)\nmodel.load_state_dict(torch.load('/kaggle/working/cnn_noise_aug_best.pth'))\n\ncnn_baseline = {0: 0.7123, 3: 0.7678, 6: 0.8493, 9: 0.9038, \n                12: 0.9429, 15: 0.9686, 18: 0.9834, 20: 0.9891}\n\nsnr_levels = [0, 3, 6, 9, 12, 15, 18, 20]\nresults = {}\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"COMPARISON: CNN Baseline vs CNN+Noise Augmentation\")\nprint(\"=\"*70)\nprint(f\"{'SNR (dB)':<10} {'CNN Baseline':<15} {'CNN+NoiseAug':<15} {'Improvement':<15}\")\nprint(\"-\"*70)\n\nfor snr in snr_levels:\n    path = f'/kaggle/input/ecg-datasets/ecg_noisy_{snr}db.csv'\n    acc = evaluate_dataset(model, path)\n    results[snr] = acc\n    \n    baseline = cnn_baseline[snr]\n    improvement = (acc - baseline) * 100\n    \n    print(f\"{snr:<10} {baseline:<15.4f} {acc:<15.4f} {improvement:+.2f}%\")\n\nprint(\"-\"*70)\navg_baseline = np.mean(list(cnn_baseline.values()))\navg_results = np.mean(list(results.values()))\navg_improvement = (avg_results - avg_baseline) * 100\n\nprint(f\"{'AVERAGE':<10} {avg_baseline:<15.4f} {avg_results:<15.4f} {avg_improvement:+.2f}%\")\nprint(\"=\"*70)\n\n# Save results\nresults_df = pd.DataFrame({\n    'SNR_dB': snr_levels,\n    'CNN_Baseline': [cnn_baseline[snr] for snr in snr_levels],\n    'CNN_NoiseAug': [results[snr] for snr in snr_levels],\n    'Improvement_%': [(results[snr] - cnn_baseline[snr])*100 for snr in snr_levels]\n})\nresults_df.to_csv('/kaggle/working/noise_aug_results.csv', index=False)\nprint(\"\\nâœ… Results saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T14:19:30.398371Z","iopub.execute_input":"2025-10-21T14:19:30.399094Z","iopub.status.idle":"2025-10-21T14:20:34.094948Z","shell.execute_reply.started":"2025-10-21T14:19:30.399069Z","shell.execute_reply":"2025-10-21T14:20:34.094244Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nCOMPARISON: CNN Baseline vs CNN+Noise Augmentation\n======================================================================\nSNR (dB)   CNN Baseline    CNN+NoiseAug    Improvement    \n----------------------------------------------------------------------\n0          0.7123          0.8854          +17.31%\n3          0.7678          0.9509          +18.31%\n6          0.8493          0.9818          +13.25%\n9          0.9038          0.9921          +8.83%\n12         0.9429          0.9957          +5.28%\n15         0.9686          0.9967          +2.81%\n18         0.9834          0.9974          +1.40%\n20         0.9891          0.9976          +0.85%\n----------------------------------------------------------------------\nAVERAGE    0.8897          0.9747          +8.50%\n======================================================================\n\nâœ… Results saved!\n","output_type":"stream"}],"execution_count":29}]}