{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13452833,"sourceType":"datasetVersion","datasetId":8539274},{"sourceId":13453138,"sourceType":"datasetVersion","datasetId":8539487}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Import Libraries\nimport os\nimport json\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import precision_recall_fscore_support, classification_report\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:17:10.147277Z","iopub.execute_input":"2025-10-25T14:17:10.148203Z","iopub.status.idle":"2025-10-25T14:17:10.153680Z","shell.execute_reply.started":"2025-10-25T14:17:10.148177Z","shell.execute_reply":"2025-10-25T14:17:10.152921Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Cell 2: Define CNN Model (Same as your architecture)\nclass ECGCNN(nn.Module):\n    def __init__(self, num_classes=5):\n        super(ECGCNN, self).__init__()\n        self.conv1 = nn.Conv1d(1, 32, kernel_size=5, stride=1, padding=2)\n        self.bn1 = nn.BatchNorm1d(32)\n        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n        \n        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n        \n        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n        \n        self.fc1 = nn.Linear(128 * 27, 256)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(256, num_classes)\n    \n    def forward(self, x):\n        x = x.unsqueeze(1)  # [B, 1, L]\n        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:17:10.164820Z","iopub.execute_input":"2025-10-25T14:17:10.165262Z","iopub.status.idle":"2025-10-25T14:17:10.171629Z","shell.execute_reply.started":"2025-10-25T14:17:10.165245Z","shell.execute_reply":"2025-10-25T14:17:10.170912Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Cell 3: Load and Preprocess Clean Data\nclean_data_path = '/kaggle/input/ecg-datasets/ecg_clean.csv'\ndf = pd.read_csv(clean_data_path)\nprint(f\"Dataset loaded: {df.shape}\")\n\n# Encode labels if needed\nif df['label'].dtype == 'object':\n    le = LabelEncoder()\n    df['label'] = le.fit_transform(df['label'])\n    label_mapping = dict(zip(le.classes_, range(len(le.classes_))))\n    print(f\"Label encoding: {label_mapping}\")\nelse:\n    label_mapping = {i: i for i in range(5)}\n\n# Ensure numeric\nfeature_cols = [col for col in df.columns if col != 'label']\nfor col in feature_cols:\n    df[col] = pd.to_numeric(df[col], errors='coerce')\ndf = df.dropna()\n\n# Convert to tensors\nX = torch.tensor(df.drop('label', axis=1).values, dtype=torch.float32)\ny = torch.tensor(df['label'].values, dtype=torch.long)\n\n# Normalize\nX = (X - X.mean(dim=0)) / (X.std(dim=0) + 1e-8)\n\nprint(f\"\\nX shape: {X.shape}, y shape: {y.shape}\")\nprint(f\"Class distribution: {np.bincount(y.numpy())}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:17:10.183302Z","iopub.execute_input":"2025-10-25T14:17:10.183700Z","iopub.status.idle":"2025-10-25T14:17:16.313578Z","shell.execute_reply.started":"2025-10-25T14:17:10.183684Z","shell.execute_reply":"2025-10-25T14:17:16.312814Z"}},"outputs":[{"name":"stdout","text":"Dataset loaded: (100033, 217)\nLabel encoding: {'A': 0, 'L': 1, 'N': 2, 'R': 3, 'V': 4}\n\nX shape: torch.Size([100033, 216]), y shape: torch.Size([100033])\nClass distribution: [ 2546  8073 75028  7257  7129]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Cell 4: Evaluation Function with All Metrics\ndef evaluate_with_metrics(model, loader, device):\n    \"\"\"Evaluate model and return comprehensive metrics\"\"\"\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    \n    # Calculate metrics\n    accuracy = (all_preds == all_labels).mean()\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_labels, all_preds, average='weighted', zero_division=0\n    )\n    \n    return {\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:17:16.315099Z","iopub.execute_input":"2025-10-25T14:17:16.315331Z","iopub.status.idle":"2025-10-25T14:17:16.321689Z","shell.execute_reply.started":"2025-10-25T14:17:16.315314Z","shell.execute_reply":"2025-10-25T14:17:16.320811Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Cell 5: Training Function for One Fold\ndef train_one_fold(train_loader, val_loader, device, num_epochs=30, patience=10):\n    \"\"\"Train baseline model for one fold (NO noise augmentation)\"\"\"\n    model = ECGCNN(num_classes=5).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    \n    best_val_f1 = 0.0\n    patience_counter = 0\n    history = {\n        'train_loss': [], 'train_acc': [],\n        'val_loss': [], 'val_acc': [], 'val_f1': []\n    }\n    \n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        train_loss, train_correct, train_total = 0, 0, 0\n        \n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            train_total += labels.size(0)\n            train_correct += (predicted == labels).sum().item()\n        \n        train_acc = train_correct / train_total\n        avg_train_loss = train_loss / len(train_loader)\n        \n        # Validation phase\n        val_metrics = evaluate_with_metrics(model, val_loader, device)\n        val_acc = val_metrics['accuracy']\n        val_f1 = val_metrics['f1_score']\n        \n        history['train_loss'].append(avg_train_loss)\n        history['train_acc'].append(train_acc)\n        history['val_acc'].append(val_acc)\n        history['val_f1'].append(val_f1)\n        \n        # Early stopping based on F1 score\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            best_model_state = model.state_dict().copy()\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        if patience_counter >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n    \n    # Load best model\n    model.load_state_dict(best_model_state)\n    \n    return model, history, best_val_f1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:17:16.322566Z","iopub.execute_input":"2025-10-25T14:17:16.323338Z","iopub.status.idle":"2025-10-25T14:17:16.334772Z","shell.execute_reply.started":"2025-10-25T14:17:16.323313Z","shell.execute_reply":"2025-10-25T14:17:16.334044Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Cell 6: K-Fold Cross-Validation Training (Baseline - Clean Data Only)\ndef train_baseline_with_kfold(X, y, k=5, num_epochs=30, patience=10, batch_size=64):\n    \"\"\"Train baseline model using stratified k-fold cross-validation (NO noise)\"\"\"\n    \n    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n    fold_results = []\n    all_histories = []\n    \n    print(\"\\n\" + \"=\"*70)\n    print(f\"BASELINE CNN TRAINING WITH {k}-FOLD CV (CLEAN DATA ONLY - NO NOISE)\")\n    print(\"=\"*70 + \"\\n\")\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        print(f\"\\n{'='*70}\")\n        print(f\"FOLD {fold+1}/{k}\")\n        print(f\"{'='*70}\")\n        \n        # Split data\n        X_train, X_val = X[train_idx], X[val_idx]\n        y_train, y_val = y[train_idx], y[val_idx]\n        \n        print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}\")\n        print(f\"Train class dist: {np.bincount(y_train.numpy())}\")\n        print(f\"Val class dist: {np.bincount(y_val.numpy())}\")\n        \n        # Create datasets (NO noise augmentation for baseline)\n        train_dataset = TensorDataset(X_train, y_train)\n        val_dataset = TensorDataset(X_val, y_val)\n        \n        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n        \n        # Train fold\n        model, history, best_val_f1 = train_one_fold(\n            train_loader, val_loader, device, num_epochs, patience\n        )\n        \n        # Evaluate on validation set\n        val_metrics = evaluate_with_metrics(model, val_loader, device)\n        \n        print(f\"\\nFold {fold+1} Results:\")\n        print(f\"  Accuracy:  {val_metrics['accuracy']:.4f}\")\n        print(f\"  Precision: {val_metrics['precision']:.4f}\")\n        print(f\"  Recall:    {val_metrics['recall']:.4f}\")\n        print(f\"  F1-Score:  {val_metrics['f1_score']:.4f}\")\n        \n        fold_results.append({\n            'fold': fold + 1,\n            'accuracy': val_metrics['accuracy'],\n            'precision': val_metrics['precision'],\n            'recall': val_metrics['recall'],\n            'f1_score': val_metrics['f1_score'],\n        })\n        \n        all_histories.append(history)\n        \n        # Save model from this fold\n        torch.save(model.state_dict(), f'/kaggle/working/baseline_model_fold_{fold+1}.pth')\n    \n    # Calculate average metrics across folds\n    avg_metrics = {\n        'accuracy_mean': np.mean([r['accuracy'] for r in fold_results]),\n        'accuracy_std': np.std([r['accuracy'] for r in fold_results]),\n        'precision_mean': np.mean([r['precision'] for r in fold_results]),\n        'precision_std': np.std([r['precision'] for r in fold_results]),\n        'recall_mean': np.mean([r['recall'] for r in fold_results]),\n        'recall_std': np.std([r['recall'] for r in fold_results]),\n        'f1_score_mean': np.mean([r['f1_score'] for r in fold_results]),\n        'f1_score_std': np.std([r['f1_score'] for r in fold_results]),\n    }\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"BASELINE K-FOLD CROSS-VALIDATION SUMMARY\")\n    print(\"=\"*70)\n    print(f\"Accuracy:  {avg_metrics['accuracy_mean']:.4f} ± {avg_metrics['accuracy_std']:.4f}\")\n    print(f\"Precision: {avg_metrics['precision_mean']:.4f} ± {avg_metrics['precision_std']:.4f}\")\n    print(f\"Recall:    {avg_metrics['recall_mean']:.4f} ± {avg_metrics['recall_std']:.4f}\")\n    print(f\"F1-Score:  {avg_metrics['f1_score_mean']:.4f} ± {avg_metrics['f1_score_std']:.4f}\")\n    print(\"=\"*70 + \"\\n\")\n    \n    return fold_results, avg_metrics, all_histories\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:17:16.335647Z","iopub.execute_input":"2025-10-25T14:17:16.335858Z","iopub.status.idle":"2025-10-25T14:17:16.354802Z","shell.execute_reply.started":"2025-10-25T14:17:16.335845Z","shell.execute_reply":"2025-10-25T14:17:16.354111Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Cell 7: Run K-Fold Cross-Validation\nfold_results, avg_metrics, all_histories = train_baseline_with_kfold(\n    X, y, \n    k=5, \n    num_epochs=30, \n    patience=10,\n    batch_size=64\n)\n\n# Save k-fold results\nresults_df = pd.DataFrame(fold_results)\nresults_df.to_csv('/kaggle/working/baseline_kfold_results.csv', index=False)\n\nwith open('/kaggle/working/baseline_avg_metrics.json', 'w') as f:\n    json.dump(avg_metrics, f, indent=2)\n\nprint(\"✅ Baseline K-fold training completed and results saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T14:17:16.356285Z","iopub.execute_input":"2025-10-25T14:17:16.356494Z","iopub.status.idle":"2025-10-25T15:38:16.973935Z","shell.execute_reply.started":"2025-10-25T14:17:16.356479Z","shell.execute_reply":"2025-10-25T15:38:16.973167Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nBASELINE CNN TRAINING WITH 5-FOLD CV (CLEAN DATA ONLY - NO NOISE)\n======================================================================\n\n\n======================================================================\nFOLD 1/5\n======================================================================\nTrain size: 80026, Val size: 20007\nTrain class dist: [ 2037  6458 60022  5806  5703]\nVal class dist: [  509  1615 15006  1451  1426]\nEarly stopping at epoch 23\n\nFold 1 Results:\n  Accuracy:  0.9950\n  Precision: 0.9950\n  Recall:    0.9950\n  F1-Score:  0.9950\n\n======================================================================\nFOLD 2/5\n======================================================================\nTrain size: 80026, Val size: 20007\nTrain class dist: [ 2037  6459 60022  5805  5703]\nVal class dist: [  509  1614 15006  1452  1426]\n\nFold 2 Results:\n  Accuracy:  0.9942\n  Precision: 0.9941\n  Recall:    0.9942\n  F1-Score:  0.9941\n\n======================================================================\nFOLD 3/5\n======================================================================\nTrain size: 80026, Val size: 20007\nTrain class dist: [ 2037  6459 60022  5805  5703]\nVal class dist: [  509  1614 15006  1452  1426]\n\nFold 3 Results:\n  Accuracy:  0.9947\n  Precision: 0.9946\n  Recall:    0.9947\n  F1-Score:  0.9946\n\n======================================================================\nFOLD 4/5\n======================================================================\nTrain size: 80027, Val size: 20006\nTrain class dist: [ 2036  6458 60023  5806  5704]\nVal class dist: [  510  1615 15005  1451  1425]\nEarly stopping at epoch 24\n\nFold 4 Results:\n  Accuracy:  0.9938\n  Precision: 0.9938\n  Recall:    0.9938\n  F1-Score:  0.9938\n\n======================================================================\nFOLD 5/5\n======================================================================\nTrain size: 80027, Val size: 20006\nTrain class dist: [ 2037  6458 60023  5806  5703]\nVal class dist: [  509  1615 15005  1451  1426]\n\nFold 5 Results:\n  Accuracy:  0.9936\n  Precision: 0.9935\n  Recall:    0.9936\n  F1-Score:  0.9935\n\n======================================================================\nBASELINE K-FOLD CROSS-VALIDATION SUMMARY\n======================================================================\nAccuracy:  0.9942 ± 0.0005\nPrecision: 0.9942 ± 0.0005\nRecall:    0.9942 ± 0.0005\nF1-Score:  0.9942 ± 0.0005\n======================================================================\n\n✅ Baseline K-fold training completed and results saved!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Cell 8: Select Best Fold Model\n# Find best fold based on F1 score\nbest_fold_idx = np.argmax([r['f1_score'] for r in fold_results])\nbest_fold = best_fold_idx + 1\n\nprint(f\"\\nBest performing fold: {best_fold}\")\nprint(f\"F1-Score: {fold_results[best_fold_idx]['f1_score']:.4f}\")\n\n# Load best model\nbest_baseline_model = ECGCNN(num_classes=5).to(device)\nbest_baseline_model.load_state_dict(torch.load(f'/kaggle/working/baseline_model_fold_{best_fold}.pth'))\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"EVALUATING BASELINE ON NOISY TEST SETS\")\nprint(\"=\"*70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:38:16.974673Z","iopub.execute_input":"2025-10-25T15:38:16.974966Z","iopub.status.idle":"2025-10-25T15:38:16.997451Z","shell.execute_reply.started":"2025-10-25T15:38:16.974944Z","shell.execute_reply":"2025-10-25T15:38:16.996891Z"}},"outputs":[{"name":"stdout","text":"\nBest performing fold: 1\nF1-Score: 0.9950\n\n======================================================================\nEVALUATING BASELINE ON NOISY TEST SETS\n======================================================================\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Cell 9: Noise Addition Function\ndef add_awgn(signal, snr_db):\n    \"\"\"Add Additive White Gaussian Noise at specified SNR level\"\"\"\n    signal_power = torch.mean(signal ** 2)\n    noise_power = signal_power / (10 ** (snr_db / 10))\n    noise = torch.randn_like(signal) * torch.sqrt(noise_power)\n    return signal + noise\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:38:16.998107Z","iopub.execute_input":"2025-10-25T15:38:16.998300Z","iopub.status.idle":"2025-10-25T15:38:17.002377Z","shell.execute_reply.started":"2025-10-25T15:38:16.998286Z","shell.execute_reply":"2025-10-25T15:38:17.001558Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Cell 10: Evaluate on Noisy Test Sets at Different SNR Levels\nsnr_levels = [0, 3, 6, 9, 12, 15, 18, 20]\nbaseline_snr_results = []\n\nprint(f\"\\n{'SNR (dB)':<10} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\nprint(\"-\"*70)\n\nfor snr in snr_levels:\n    # Check if pre-made noisy CSV exists\n    noisy_csv_path = f'/kaggle/input/ecg-datasets/ecg_noisy_{snr}db.csv'\n    \n    if os.path.exists(noisy_csv_path):\n        # Load pre-made noisy dataset\n        df_noisy = pd.read_csv(noisy_csv_path)\n        \n        if df_noisy['label'].dtype == 'object':\n            le = LabelEncoder()\n            df_noisy['label'] = le.fit_transform(df_noisy['label'])\n        \n        feature_cols = [col for col in df_noisy.columns if col != 'label']\n        for col in feature_cols:\n            df_noisy[col] = pd.to_numeric(df_noisy[col], errors='coerce')\n        df_noisy = df_noisy.dropna()\n        \n        X_noisy = torch.tensor(df_noisy.drop('label', axis=1).values, dtype=torch.float32)\n        y_noisy = torch.tensor(df_noisy['label'].values, dtype=torch.long)\n        X_noisy = (X_noisy - X_noisy.mean(dim=0)) / (X_noisy.std(dim=0) + 1e-8)\n    else:\n        # Generate noisy data on-the-fly from clean data\n        X_noisy = torch.stack([add_awgn(x, snr) for x in X], dim=0)\n        y_noisy = y.clone()\n    \n    # Create loader\n    noisy_dataset = TensorDataset(X_noisy, y_noisy)\n    noisy_loader = DataLoader(noisy_dataset, batch_size=64, shuffle=False)\n    \n    # Evaluate\n    metrics = evaluate_with_metrics(best_baseline_model, noisy_loader, device)\n    \n    baseline_snr_results.append({\n        'snr_db': snr,\n        'baseline_accuracy': metrics['accuracy'],\n        'baseline_precision': metrics['precision'],\n        'baseline_recall': metrics['recall'],\n        'baseline_f1_score': metrics['f1_score']\n    })\n    \n    print(f\"{snr:<10} {metrics['accuracy']:<12.4f} {metrics['precision']:<12.4f} \"\n          f\"{metrics['recall']:<12.4f} {metrics['f1_score']:<12.4f}\")\n\nprint(\"-\"*70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:38:17.003113Z","iopub.execute_input":"2025-10-25T15:38:17.003420Z","iopub.status.idle":"2025-10-25T15:39:48.914192Z","shell.execute_reply.started":"2025-10-25T15:38:17.003400Z","shell.execute_reply":"2025-10-25T15:39:48.913538Z"}},"outputs":[{"name":"stdout","text":"\nSNR (dB)   Accuracy     Precision    Recall       F1-Score    \n----------------------------------------------------------------------\n0          0.7537       0.7252       0.7537       0.7064      \n3          0.8014       0.8001       0.8014       0.7814      \n6          0.8638       0.8731       0.8638       0.8608      \n9          0.9135       0.9240       0.9135       0.9157      \n12         0.9407       0.9508       0.9407       0.9438      \n15         0.9577       0.9673       0.9577       0.9611      \n18         0.9738       0.9806       0.9738       0.9761      \n20         0.9836       0.9866       0.9836       0.9846      \n----------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Cell 11: Save Baseline SNR Results (FIXED)\nbaseline_snr_df = pd.DataFrame(baseline_snr_results)\nbaseline_snr_df.to_csv('/kaggle/working/baseline_snr_results.csv', index=False)\n\n# Calculate and save summary statistics\nsummary_stats = {\n    'model': 'Baseline CNN (Clean Data Only - K-Fold CV)',\n    'k_folds': 5,\n    'best_fold': int(best_fold),  # ← Convert to Python int\n    'snr_levels': [int(x) for x in snr_levels],  # ← Convert to Python int list\n    'clean_data_performance': {\n        'accuracy_mean': float(avg_metrics['accuracy_mean']),  # ← Convert to Python float\n        'accuracy_std': float(avg_metrics['accuracy_std']),\n        'f1_score_mean': float(avg_metrics['f1_score_mean']),\n        'f1_score_std': float(avg_metrics['f1_score_std'])\n    },\n    'noisy_data_performance': {\n        'avg_accuracy': float(baseline_snr_df['baseline_accuracy'].mean()),\n        'avg_precision': float(baseline_snr_df['baseline_precision'].mean()),\n        'avg_recall': float(baseline_snr_df['baseline_recall'].mean()),\n        'avg_f1_score': float(baseline_snr_df['baseline_f1_score'].mean()),\n        'worst_accuracy_snr': int(baseline_snr_df.loc[baseline_snr_df['baseline_accuracy'].idxmin(), 'snr_db']),\n        'worst_accuracy_value': float(baseline_snr_df['baseline_accuracy'].min()),\n        'best_accuracy_snr': int(baseline_snr_df.loc[baseline_snr_df['baseline_accuracy'].idxmax(), 'snr_db']),\n        'best_accuracy_value': float(baseline_snr_df['baseline_accuracy'].max())\n    }\n}\n\nwith open('/kaggle/working/baseline_summary.json', 'w') as f:\n    json.dump(summary_stats, f, indent=2)\n\nprint(\"\\n Baseline SNR evaluation results saved!\")\nprint(\"\\nFiles created:\")\nprint(\"  - baseline_kfold_results.csv: K-fold validation metrics per fold\")\nprint(\"  - baseline_avg_metrics.json: Average metrics across folds\")\nprint(\"  - baseline_snr_results.csv: Performance metrics at each SNR level\")\nprint(\"  - baseline_summary.json: Complete summary statistics\")\nprint(\"  - baseline_model_fold_1.pth to baseline_model_fold_5.pth: Saved models\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:44:18.725853Z","iopub.execute_input":"2025-10-25T15:44:18.726191Z","iopub.status.idle":"2025-10-25T15:44:18.737019Z","shell.execute_reply.started":"2025-10-25T15:44:18.726172Z","shell.execute_reply":"2025-10-25T15:44:18.736395Z"}},"outputs":[{"name":"stdout","text":"\n Baseline SNR evaluation results saved!\n\nFiles created:\n  - baseline_kfold_results.csv: K-fold validation metrics per fold\n  - baseline_avg_metrics.json: Average metrics across folds\n  - baseline_snr_results.csv: Performance metrics at each SNR level\n  - baseline_summary.json: Complete summary statistics\n  - baseline_model_fold_1.pth to baseline_model_fold_5.pth: Saved models\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Cell 12: Display Complete Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"COMPLETE BASELINE CNN SUMMARY\")\nprint(\"=\"*70)\n\nprint(\"\\n1. K-Fold Cross-Validation Results (Clean Data):\")\nprint(f\"   Accuracy:  {avg_metrics['accuracy_mean']:.4f} ± {avg_metrics['accuracy_std']:.4f}\")\nprint(f\"   Precision: {avg_metrics['precision_mean']:.4f} ± {avg_metrics['precision_std']:.4f}\")\nprint(f\"   Recall:    {avg_metrics['recall_mean']:.4f} ± {avg_metrics['recall_std']:.4f}\")\nprint(f\"   F1-Score:  {avg_metrics['f1_score_mean']:.4f} ± {avg_metrics['f1_score_std']:.4f}\")\n\nprint(\"\\n2. Average Performance on Noisy Data (0-20 dB SNR):\")\nprint(f\"   Accuracy:  {summary_stats['noisy_data_performance']['avg_accuracy']:.4f}\")\nprint(f\"   Precision: {summary_stats['noisy_data_performance']['avg_precision']:.4f}\")\nprint(f\"   Recall:    {summary_stats['noisy_data_performance']['avg_recall']:.4f}\")\nprint(f\"   F1-Score:  {summary_stats['noisy_data_performance']['avg_f1_score']:.4f}\")\n\nprint(\"\\n3. Performance Range on Noisy Data:\")\nprint(f\"   Best:  {summary_stats['noisy_data_performance']['best_accuracy_value']:.4f} at SNR {summary_stats['noisy_data_performance']['best_accuracy_snr']} dB\")\nprint(f\"   Worst: {summary_stats['noisy_data_performance']['worst_accuracy_value']:.4f} at SNR {summary_stats['noisy_data_performance']['worst_accuracy_snr']} dB\")\nprint(f\"   Degradation: {(summary_stats['noisy_data_performance']['best_accuracy_value'] - summary_stats['noisy_data_performance']['worst_accuracy_value']) * 100:.2f}%\")\n\nprint(\"\\n4. Best Fold Model Used:\")\nprint(f\"   Fold: {best_fold}\")\nprint(f\"   F1-Score: {fold_results[best_fold_idx]['f1_score']:.4f}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"\\n✅ Baseline training and evaluation complete!\")\nprint(\"\\nNext Steps:\")\nprint(\"1. Run the k-fold training script WITH noise augmentation\")\nprint(\"2. Use the visualization script to compare baseline vs noise-augmented results\")\nprint(\"=\"*70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:44:26.596433Z","iopub.execute_input":"2025-10-25T15:44:26.596702Z","iopub.status.idle":"2025-10-25T15:44:26.604048Z","shell.execute_reply.started":"2025-10-25T15:44:26.596683Z","shell.execute_reply":"2025-10-25T15:44:26.603181Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nCOMPLETE BASELINE CNN SUMMARY\n======================================================================\n\n1. K-Fold Cross-Validation Results (Clean Data):\n   Accuracy:  0.9942 ± 0.0005\n   Precision: 0.9942 ± 0.0005\n   Recall:    0.9942 ± 0.0005\n   F1-Score:  0.9942 ± 0.0005\n\n2. Average Performance on Noisy Data (0-20 dB SNR):\n   Accuracy:  0.8985\n   Precision: 0.9010\n   Recall:    0.8985\n   F1-Score:  0.8913\n\n3. Performance Range on Noisy Data:\n   Best:  0.9836 at SNR 20 dB\n   Worst: 0.7537 at SNR 0 dB\n   Degradation: 22.99%\n\n4. Best Fold Model Used:\n   Fold: 1\n   F1-Score: 0.9950\n\n======================================================================\n\n✅ Baseline training and evaluation complete!\n\nNext Steps:\n1. Run the k-fold training script WITH noise augmentation\n2. Use the visualization script to compare baseline vs noise-augmented results\n======================================================================\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Cell 13: Display Detailed Results Table\nprint(\"\\n\" + \"=\"*70)\nprint(\"DETAILED BASELINE RESULTS BY SNR LEVEL\")\nprint(\"=\"*70 + \"\\n\")\n\nprint(baseline_snr_df.to_string(index=False))\nprint(\"\\n\" + \"=\"*70)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T15:44:33.203506Z","iopub.execute_input":"2025-10-25T15:44:33.203770Z","iopub.status.idle":"2025-10-25T15:44:33.214281Z","shell.execute_reply.started":"2025-10-25T15:44:33.203751Z","shell.execute_reply":"2025-10-25T15:44:33.213558Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nDETAILED BASELINE RESULTS BY SNR LEVEL\n======================================================================\n\n snr_db  baseline_accuracy  baseline_precision  baseline_recall  baseline_f1_score\n      0           0.753711            0.725188         0.753711           0.706447\n      3           0.801356            0.800076         0.801356           0.781382\n      6           0.863805            0.873064         0.863805           0.860777\n      9           0.913459            0.923952         0.913459           0.915745\n     12           0.940750            0.950837         0.940750           0.943801\n     15           0.957664            0.967308         0.957664           0.961088\n     18           0.973759            0.980641         0.973759           0.976147\n     20           0.983635            0.986614         0.983635           0.984634\n\n======================================================================\n","output_type":"stream"}],"execution_count":18}]}